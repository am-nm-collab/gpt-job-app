from dotenv import load_dotenv

# CONFIG

# OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')
# DB_OUTPUT_DIR=os.getenv('DB_OUTPUT_DIR').strip("/")

# UTILS

def pretty_print_resume(resume_json):
  # For a base resume or a completed resume, pretty print it to the commandline.

def pretty_print_job_history(job_history):
  # For a single job history, pretty print it to the commandline.

# DB LOGIC
# Note: These functions will be modified heavily when we move to a real datastore. Right now its just a flat file.

def set_conversation_history(conversation_history):
  # Save the entire conversation history in the DB.

def set_linkedin_work_history(linkedin_work_history):
  # Save the linkedin work history provided by the user in the DB

def set_base_resume(base_resume):
  # Save the base resume generated by the LLM from the complete work history given by the user in the database

def set_resume(resume):
  # Save the taiilored resume along with the job description data (either extracted or provided by the user) in the database

def set_resume_markdown(resume):
  # Save the taiilored resume as a markdown file in the filesystem and return the path.

def get_all_user_data(user_id):
  # Read back the entire JSON data stored for a user. This is used temporarily while we wait for a real database, as we need to read, update, and write back the entire dataset when we update any fields in flat files.

def get_conversation_history(conversation_history):
  # Load the entire conversation history from the DB.

def get_linkedin_work_history(linkedin_work_history):
  # Load the linkedin work history provided by the user from the DB

def get_base_resume(base_resume):
  # Load the base resume generated by the LLM from the complete work history given by the user from the DB

def get_resume(resume):
  # Load the taiilored resume along with the job description data (either extracted or provided by the user) from the DB


# EXTERNAL API LOGIC

def get_linkedin_profile(linkedin_url):
  # Placeholder of dummy data until we get real API access to linkedin
  {
    "work_history": [
      {
        "company": {
          "id": "123456",
          "name": "ABC Corporation",
          "industry": "Information Technology and Services"
        },
        "position": {
          "id": "987654",
          "title": "Software Engineer",
          "description": "Responsible for developing and maintaining web applications using modern web technologies."
        },
        "location": "San Francisco, California, United States",
        "start_date": "2018-06-01",
        "end_date": "2021-08-31"
      },
      {
        "company": {
          "id": "234567",
          "name": "XYZ Inc.",
          "industry": "Computer Software"
        },
        "position": {
          "id": "876543",
          "title": "Senior Software Engineer",
          "description": "Led a team of software engineers to build scalable and reliable software solutions."
        },
        "location": "New York, New York, United States",
        "start_date": "2021-09-01",
        "end_date": "present"
      }
    ]
  }


# COMMANDLINE LOGIC

def gather_missing_work_history(work_history):
  # Given a LinkedIn work history, gather any missing work history from the user via commandline prompts. Save the updated data in the DB.

def gather_specific_work_history(base_resume, job_description):
  # Given a base resume and a specific job description, gather any additional information that might help make the resume better tailored to the job description. Update the base_resume with the new information.

# LLM LOGIC
def distill_work_history(work_history):
  # Given a work history, distill down to the salient points in a "base resume" in JSON form to make rendering easier

def generate_missing_work_history_request(base_resume, job_description):
  # Given a linkedin work history, distill down to a structured format and generate a list of questions to prompt the user for more information to create a more complete base resume with required fields like activities, skills, and measurable impact.
  # Note that you may want to code some more complex logic here to enter into and come out of holes based on user responses. An example is if you ask for impact the user had, but they don't give you something measurable, prompt until you get the info you need.

def generate_specific_work_history_request(base_resume, job_description):
  # Given a base resume and a job description, generate a list of questions to prompt the user for more information in order to better tailor their resume for the role.

def generate_final_resume(base_resume, job_description)


def main():

  # STARTING FLOW

  # Main flow of commandline requests

  # Prompt user for linkedin profile

  # Enter flow of gathering missing work history via prompts

  # Create base resume and present it to the user with the pretty print utils

  # WHILE TRUE LOOP (stay until user exits)

  # Prompt user for job description

  # Enter flow of gathering specific work history via prompts

  # Create final resume and present it to the user with the pretty print utils. Tell them the directory where the resume markdown file is stored

  # Prompt user for another job description

if __name__ == '__main__':
  main()
